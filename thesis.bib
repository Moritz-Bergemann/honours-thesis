
@techreport{zhang_topformer_2022,
	title = {{TopFormer}: {Token} {Pyramid} {Transformer} for {Mobile} {Semantic} {Segmentation}},
	shorttitle = {{TopFormer}},
	url = {http://arxiv.org/abs/2204.05525},
	number = {arXiv:2204.05525},
	urldate = {2022-06-10},
	institution = {arXiv},
	author = {Zhang, Wenqiang and Huang, Zilong and Luo, Guozhong and Chen, Tao and Wang, Xinggang and Liu, Wenyu and Yu, Gang and Shen, Chunhua},
	month = apr,
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{xu_cdtrans_2021,
	title = {{CDTrans}: {Cross}-domain {Transformer} for {Unsupervised} {Domain} {Adaptation}},
	shorttitle = {{CDTrans}},
	url = {http://arxiv.org/abs/2109.06165},
	number = {arXiv:2109.06165},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Xu, Tongkun and Chen, Weihua and Wang, Pichao and Wang, Fan and Li, Hao and Jin, Rong},
	month = sep,
	year = {2021},
	doi = {10.48550/arXiv.2109.06165},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{larochelle_zero-data_2008,
	title = {Zero-data {Learning} of {New} {Tasks}},
	language = {en},
	author = {Larochelle, Hugo and Erhan, Dumitru and Bengio, Yoshua},
	year = {2008},
	pages = {6},
}

@article{chapelle_semi-supervised_2005,
	title = {Semi-{Supervised} {Classiﬁcation} by {Low} {Density} {Separation}},
	language = {en},
	author = {Chapelle, Olivier and Zien, Alexander},
	year = {2005},
	pages = {8},
}

@article{radford_language_2019,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	language = {en},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	year = {2019},
	pages = {24},
}

@article{geiger_vision_2013,
	title = {Vision meets robotics: {The} {KITTI} dataset},
	volume = {32},
	issn = {0278-3649, 1741-3176},
	shorttitle = {Vision meets robotics},
	url = {http://journals.sagepub.com/doi/10.1177/0278364913491297},
	doi = {10.1177/0278364913491297},
	language = {en},
	number = {11},
	urldate = {2022-06-10},
	journal = {The International Journal of Robotics Research},
	author = {Geiger, A and Lenz, P and Stiller, C and Urtasun, R},
	month = sep,
	year = {2013},
	pages = {1231--1237},
}

@techreport{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	number = {arXiv:1505.04597},
	urldate = {2022-06-10},
	institution = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	doi = {10.48550/arXiv.1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{saenko_adapting_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Adapting {Visual} {Category} {Models} to {New} {Domains}},
	isbn = {978-3-642-15561-1},
	doi = {10.1007/978-3-642-15561-1_16},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer},
	author = {Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	year = {2010},
	keywords = {Domain Adaptation, Source Domain, Support Vector Machine, Target Domain, Visual Domain},
	pages = {213--226},
}

@techreport{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2005.14165},
	number = {arXiv:2005.14165},
	urldate = {2022-06-10},
	institution = {arXiv},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = jul,
	year = {2020},
	doi = {10.48550/arXiv.2005.14165},
	keywords = {Computer Science - Computation and Language},
}

@techreport{karras_progressive_2018,
	title = {Progressive {Growing} of {GANs} for {Improved} {Quality}, {Stability}, and {Variation}},
	url = {http://arxiv.org/abs/1710.10196},
	number = {arXiv:1710.10196},
	urldate = {2022-06-10},
	institution = {arXiv},
	author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	month = feb,
	year = {2018},
	doi = {10.48550/arXiv.1710.10196},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@techreport{yu_bisenet_2018,
	title = {{BiSeNet}: {Bilateral} {Segmentation} {Network} for {Real}-time {Semantic} {Segmentation}},
	shorttitle = {{BiSeNet}},
	url = {http://arxiv.org/abs/1808.00897},
	number = {arXiv:1808.00897},
	urldate = {2022-06-10},
	institution = {arXiv},
	author = {Yu, Changqian and Wang, Jingbo and Peng, Chao and Gao, Changxin and Yu, Gang and Sang, Nong},
	month = aug,
	year = {2018},
	doi = {10.48550/arXiv.1808.00897},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{lin_maritime_2017,
	title = {Maritime {Semantic} {Labeling} of {Optical} {Remote} {Sensing} {Images} with {Multi}-{Scale} {Fully} {Convolutional} {Network}},
	volume = {9},
	doi = {10.3390/rs9050480},
	journal = {Remote Sensing},
	author = {Lin, Haoning and Shi, Zhenwei and Zou, Zhengxia},
	month = may,
	year = {2017},
	pages = {480},
}

@techreport{hoffman_cycada_2017,
	title = {{CyCADA}: {Cycle}-{Consistent} {Adversarial} {Domain} {Adaptation}},
	shorttitle = {{CyCADA}},
	url = {http://arxiv.org/abs/1711.03213},
	number = {arXiv:1711.03213},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Hoffman, Judy and Tzeng, Eric and Park, Taesung and Zhu, Jun-Yan and Isola, Phillip and Saenko, Kate and Efros, Alexei A. and Darrell, Trevor},
	month = dec,
	year = {2017},
	doi = {10.48550/arXiv.1711.03213},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{lin_refinenet_2016,
	title = {{RefineNet}: {Multi}-{Path} {Refinement} {Networks} for {High}-{Resolution} {Semantic} {Segmentation}},
	shorttitle = {{RefineNet}},
	url = {http://arxiv.org/abs/1611.06612},
	number = {arXiv:1611.06612},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Lin, Guosheng and Milan, Anton and Shen, Chunhua and Reid, Ian},
	month = nov,
	year = {2016},
	doi = {10.48550/arXiv.1611.06612},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{bermudez-chacon_domain-adaptive_2018,
	title = {A domain-adaptive two-stream {U}-{Net} for electron microscopy image segmentation},
	doi = {10.1109/ISBI.2018.8363602},
	booktitle = {2018 {IEEE} 15th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2018)},
	author = {Bermúdez-Chacón, Róger and Márquez-Neila, Pablo and Salzmann, Mathieu and Fua, Pascal},
	month = apr,
	year = {2018},
	keywords = {Image segmentation, Training, Domain Adaptation, Electron Microscopy, Indexes, Machine Learning, Mice, Standards, Synapses, Training data},
	pages = {400--404},
}

@inproceedings{ros_synthia_2016,
	address = {Las Vegas, NV, USA},
	title = {The {SYNTHIA} {Dataset}: {A} {Large} {Collection} of {Synthetic} {Images} for {Semantic} {Segmentation} of {Urban} {Scenes}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {The {SYNTHIA} {Dataset}},
	url = {http://ieeexplore.ieee.org/document/7780721/},
	doi = {10.1109/CVPR.2016.352},
	language = {en},
	urldate = {2022-06-09},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Ros, German and Sellart, Laura and Materzynska, Joanna and Vazquez, David and Lopez, Antonio M.},
	month = jun,
	year = {2016},
	pages = {3234--3243},
}

@techreport{richter_playing_2016,
	title = {Playing for {Data}: {Ground} {Truth} from {Computer} {Games}},
	shorttitle = {Playing for {Data}},
	url = {http://arxiv.org/abs/1608.02192},
	number = {arXiv:1608.02192},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Richter, Stephan R. and Vineet, Vibhav and Roth, Stefan and Koltun, Vladlen},
	month = aug,
	year = {2016},
	doi = {10.48550/arXiv.1608.02192},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, I.4.8},
}

@techreport{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	number = {arXiv:1406.2661},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	doi = {10.48550/arXiv.1406.2661},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{gretton_kernel_2006,
	title = {A {Kernel} {Method} for the {Two}-{Sample}-{Problem}},
	volume = {19},
	urldate = {2022-06-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Gretton, Arthur and Borgwardt, Karsten and Rasch, Malte and Schölkopf, Bernhard and Smola, Alex},
	year = {2006},
}

@techreport{sun_return_2015,
	title = {Return of {Frustratingly} {Easy} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/1511.05547},
	number = {arXiv:1511.05547},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Sun, Baochen and Feng, Jiashi and Saenko, Kate},
	month = dec,
	year = {2015},
	doi = {10.48550/arXiv.1511.05547},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence},
}

@techreport{tsai_multimodal_2019,
	title = {Multimodal {Transformer} for {Unaligned} {Multimodal} {Language} {Sequences}},
	url = {http://arxiv.org/abs/1906.00295},
	number = {arXiv:1906.00295},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J. Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
	month = jun,
	year = {2019},
	keywords = {Computer Science - Computation and Language},
}

@techreport{li_trear_2021,
	title = {Trear: {Transformer}-based {RGB}-{D} {Egocentric} {Action} {Recognition}},
	shorttitle = {Trear},
	url = {http://arxiv.org/abs/2101.03904},
	number = {arXiv:2101.03904},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Li, Xiangyu and Hou, Yonghong and Wang, Pichao and Gao, Zhimin and Xu, Mingliang and Li, Wanqing},
	month = jan,
	year = {2021},
	doi = {10.48550/arXiv.2101.03904},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wang_exploring_2021,
	title = {Exploring {Sequence} {Feature} {Alignment} for {Domain} {Adaptive} {Detection} {Transformers}},
	url = {http://arxiv.org/abs/2107.12636},
	doi = {10.1145/3474085.3475317},
	urldate = {2022-06-09},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Multimedia}},
	author = {Wang, Wen and Cao, Yang and Zhang, Jing and He, Fengxiang and Zha, Zheng-Jun and Wen, Yonggang and Tao, Dacheng},
	month = oct,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, 68T45 (Primary) 68T07 (Secondary), I.2.10, I.4.9},
	pages = {1730--1738},
}

@techreport{yang_transformer-based_2021,
	title = {Transformer-{Based} {Source}-{Free} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/2105.14138},
	number = {arXiv:2105.14138},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Yang, Guanglei and Tang, Hao and Zhong, Zhun and Ding, Mingli and Shao, Ling and Sebe, Nicu and Ricci, Elisa},
	month = may,
	year = {2021},
	doi = {10.48550/arXiv.2105.14138},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
}

@techreport{liu_multi-task_2019,
	title = {Multi-{Task} {Deep} {Neural} {Networks} for {Natural} {Language} {Understanding}},
	url = {http://arxiv.org/abs/1901.11504},
	number = {arXiv:1901.11504},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
	month = may,
	year = {2019},
	doi = {10.48550/arXiv.1901.11504},
	keywords = {Computer Science - Computation and Language},
}

@techreport{shakeri_end--end_2020,
	title = {End-to-{End} {Synthetic} {Data} {Generation} for {Domain} {Adaptation} of {Question} {Answering} {Systems}},
	url = {http://arxiv.org/abs/2010.06028},
	number = {arXiv:2010.06028},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Shakeri, Siamak and Santos, Cicero Nogueira dos and Zhu, Henry and Ng, Patrick and Nan, Feng and Wang, Zhiguo and Nallapati, Ramesh and Xiang, Bing},
	month = oct,
	year = {2020},
	doi = {10.48550/arXiv.2010.06028},
	keywords = {Computer Science - Computation and Language},
}

@techreport{wright_transformer_2020,
	title = {Transformer {Based} {Multi}-{Source} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/2009.07806},
	number = {arXiv:2009.07806},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Wright, Dustin and Augenstein, Isabelle},
	month = sep,
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Statistics - Machine Learning},
}

@techreport{wang_differential_2020,
	title = {Differential {Treatment} for {Stuff} and {Things}: {A} {Simple} {Unsupervised} {Domain} {Adaptation} {Method} for {Semantic} {Segmentation}},
	shorttitle = {Differential {Treatment} for {Stuff} and {Things}},
	url = {http://arxiv.org/abs/2003.08040},
	number = {arXiv:2003.08040},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Wang, Zhonghao and Yu, Mo and Wei, Yunchao and Feris, Rogerio and Xiong, Jinjun and Hwu, Wen-mei and Huang, Thomas S. and Shi, Humphrey},
	month = jun,
	year = {2020},
	doi = {10.48550/arXiv.2003.08040},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@techreport{li_bidirectional_2019,
	title = {Bidirectional {Learning} for {Domain} {Adaptation} of {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1904.10620},
	number = {arXiv:1904.10620},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Li, Yunsheng and Yuan, Lu and Vasconcelos, Nuno},
	month = apr,
	year = {2019},
	doi = {10.48550/arXiv.1904.10620},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{benjdira_unsupervised_2019,
	title = {Unsupervised {Domain} {Adaptation} using {Generative} {Adversarial} {Networks} for {Semantic} {Segmentation} of {Aerial} {Images}},
	volume = {11},
	issn = {2072-4292},
	url = {http://arxiv.org/abs/1905.03198},
	doi = {10.3390/rs11111369},
	number = {11},
	urldate = {2022-06-09},
	journal = {Remote Sensing},
	author = {Benjdira, Bilel and Bazi, Yakoub and Koubaa, Anis and Ouni, Kais},
	month = jun,
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {1369},
}

@techreport{vu_advent_2019,
	title = {{ADVENT}: {Adversarial} {Entropy} {Minimization} for {Domain} {Adaptation} in {Semantic} {Segmentation}},
	shorttitle = {{ADVENT}},
	url = {http://arxiv.org/abs/1811.12833},
	number = {arXiv:1811.12833},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Vu, Tuan-Hung and Jain, Himalaya and Bucher, Maxime and Cord, Matthieu and Pérez, Patrick},
	month = apr,
	year = {2019},
	doi = {10.48550/arXiv.1811.12833},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{wu_dannet_2021,
	title = {{DANNet}: {A} {One}-{Stage} {Domain} {Adaptation} {Network} for {Unsupervised} {Nighttime} {Semantic} {Segmentation}},
	shorttitle = {{DANNet}},
	url = {http://arxiv.org/abs/2104.10834},
	number = {arXiv:2104.10834},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Wu, Xinyi and Wu, Zhenyao and Guo, Hao and Ju, Lili and Wang, Song},
	month = apr,
	year = {2021},
	doi = {10.48550/arXiv.2104.10834},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore} {Full}-{Text} {PDF}:},
	url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8363602&tag=1},
	urldate = {2022-06-09},
}

@techreport{hoffman_fcns_2016,
	title = {{FCNs} in the {Wild}: {Pixel}-level {Adversarial} and {Constraint}-based {Adaptation}},
	shorttitle = {{FCNs} in the {Wild}},
	url = {http://arxiv.org/abs/1612.02649},
	number = {arXiv:1612.02649},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Hoffman, Judy and Wang, Dequan and Yu, Fisher and Darrell, Trevor},
	month = dec,
	year = {2016},
	doi = {10.48550/arXiv.1612.02649},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{csurka_unsupervised_2021,
	title = {Unsupervised {Domain} {Adaptation} for {Semantic} {Image} {Segmentation}: a {Comprehensive} {Survey}},
	shorttitle = {Unsupervised {Domain} {Adaptation} for {Semantic} {Image} {Segmentation}},
	url = {http://arxiv.org/abs/2112.03241},
	number = {arXiv:2112.03241},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Csurka, Gabriela and Volpi, Riccardo and Chidlovskii, Boris},
	month = dec,
	year = {2021},
	doi = {10.48550/arXiv.2112.03241},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, I.2, I.4.6},
}

@techreport{liang_we_2021,
	title = {Do {We} {Really} {Need} to {Access} the {Source} {Data}? {Source} {Hypothesis} {Transfer} for {Unsupervised} {Domain} {Adaptation}},
	shorttitle = {Do {We} {Really} {Need} to {Access} the {Source} {Data}?},
	url = {http://arxiv.org/abs/2002.08546},
	number = {arXiv:2002.08546},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Liang, Jian and Hu, Dapeng and Feng, Jiashi},
	month = jun,
	year = {2021},
	doi = {10.48550/arXiv.2002.08546},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@techreport{kamnitsas_transductive_2021,
	title = {Transductive image segmentation: {Self}-training and effect of uncertainty estimation},
	shorttitle = {Transductive image segmentation},
	url = {http://arxiv.org/abs/2107.08964},
	number = {arXiv:2107.08964},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Kamnitsas, Konstantinos and Winzeck, Stefan and Kornaropoulos, Evgenios N. and Whitehouse, Daniel and Englman, Cameron and Phyu, Poe and Pao, Norman and Menon, David K. and Rueckert, Daniel and Das, Tilak and Newcombe, Virginia F. J. and Glocker, Ben},
	month = aug,
	year = {2021},
	doi = {10.48550/arXiv.2107.08964},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{zhu_unpaired_2020,
	title = {Unpaired {Image}-to-{Image} {Translation} using {Cycle}-{Consistent} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1703.10593},
	number = {arXiv:1703.10593},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	month = aug,
	year = {2020},
	doi = {10.48550/arXiv.1703.10593},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{mirza_conditional_2014,
	title = {Conditional {Generative} {Adversarial} {Nets}},
	url = {http://arxiv.org/abs/1411.1784},
	number = {arXiv:1411.1784},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Mirza, Mehdi and Osindero, Simon},
	month = nov,
	year = {2014},
	doi = {10.48550/arXiv.1411.1784},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{rozantsev_beyond_2019,
	title = {Beyond {Sharing} {Weights} for {Deep} {Domain} {Adaptation}},
	volume = {41},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {http://arxiv.org/abs/1603.06432},
	doi = {10.1109/TPAMI.2018.2814042},
	number = {4},
	urldate = {2022-06-09},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Rozantsev, Artem and Salzmann, Mathieu and Fua, Pascal},
	month = apr,
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {801--814},
}

@techreport{ganin_domain-adversarial_2016,
	title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.07818},
	number = {arXiv:1505.07818},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	month = may,
	year = {2016},
	doi = {10.48550/arXiv.1505.07818},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@techreport{zou_domain_2018,
	title = {Domain {Adaptation} for {Semantic} {Segmentation} via {Class}-{Balanced} {Self}-{Training}},
	url = {http://arxiv.org/abs/1810.07911},
	number = {arXiv:1810.07911},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Zou, Yang and Yu, Zhiding and Kumar, B. V. K. Vijaya and Wang, Jinsong},
	month = oct,
	year = {2018},
	doi = {10.48550/arXiv.1810.07911},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Multimedia},
}

@techreport{yang_tvt_2021,
	title = {{TVT}: {Transferable} {Vision} {Transformer} for {Unsupervised} {Domain} {Adaptation}},
	shorttitle = {{TVT}},
	url = {http://arxiv.org/abs/2108.05988},
	number = {arXiv:2108.05988},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Yang, Jinyu and Liu, Jingjing and Xu, Ning and Huang, Junzhou},
	month = nov,
	year = {2021},
	doi = {10.48550/arXiv.2108.05988},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{wang_domain_2022,
	title = {Domain {Adaptation} via {Bidirectional} {Cross}-{Attention} {Transformer}},
	url = {http://arxiv.org/abs/2201.05887},
	number = {arXiv:2201.05887},
	urldate = {2022-06-09},
	institution = {arXiv},
	author = {Wang, Xiyu and Guo, Pengxin and Zhang, Yu},
	month = jan,
	year = {2022},
	doi = {10.48550/arXiv.2201.05887},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@techreport{farahani_brief_2020,
	title = {A {Brief} {Review} of {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/2010.03978},
	number = {arXiv:2010.03978},
	urldate = {2022-06-05},
	institution = {arXiv},
	author = {Farahani, Abolfazl and Voghoei, Sahar and Rasheed, Khaled and Arabnia, Hamid R.},
	month = oct,
	year = {2020},
	doi = {10.48550/arXiv.2010.03978},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@techreport{cordts_cityscapes_2016,
	title = {The {Cityscapes} {Dataset} for {Semantic} {Urban} {Scene} {Understanding}},
	url = {http://arxiv.org/abs/1604.01685},
	number = {arXiv:1604.01685},
	urldate = {2022-06-05},
	institution = {arXiv},
	author = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
	month = apr,
	year = {2016},
	doi = {10.48550/arXiv.1604.01685},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{pan_survey_2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2009.191},
	number = {10},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, Sinno Jialin and Yang, Qiang},
	month = oct,
	year = {2010},
	keywords = {machine learning, Transfer learning, Training data, Data mining, data mining., Knowledge engineering, Knowledge transfer, Labeling, Learning systems, Machine learning, Machine learning algorithms, Space technology, survey, Testing},
	pages = {1345--1359},
}

@techreport{chen_attention_2016,
	title = {Attention to {Scale}: {Scale}-aware {Semantic} {Image} {Segmentation}},
	shorttitle = {Attention to {Scale}},
	url = {http://arxiv.org/abs/1511.03339},
	number = {arXiv:1511.03339},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Chen, Liang-Chieh and Yang, Yi and Wang, Jiang and Xu, Wei and Yuille, Alan L.},
	month = jun,
	year = {2016},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@book{zhang_dive_2019,
	title = {Dive into {Deep} {Learning}},
	author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
	year = {2019},
}

@techreport{poudel_fast-scnn_2019,
	title = {Fast-{SCNN}: {Fast} {Semantic} {Segmentation} {Network}},
	shorttitle = {Fast-{SCNN}},
	url = {http://arxiv.org/abs/1902.04502},
	number = {arXiv:1902.04502},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Poudel, Rudra P. K. and Liwicki, Stephan and Cipolla, Roberto},
	month = feb,
	year = {2019},
	doi = {10.48550/arXiv.1902.04502},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{chen_learning_2017,
	title = {Learning {Efficient} {Object} {Detection} {Models} with {Knowledge} {Distillation}},
	volume = {30},
	urldate = {2022-06-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Chen, Guobin and Choi, Wongun and Yu, Xiang and Han, Tony and Chandraker, Manmohan},
	year = {2017},
}

@techreport{bai_dynamically_2021,
	title = {Dynamically pruning segformer for efficient semantic segmentation},
	url = {http://arxiv.org/abs/2111.09499},
	number = {arXiv:2111.09499},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Bai, Haoli and Mao, Hongda and Nair, Dinesh},
	month = nov,
	year = {2021},
	doi = {10.48550/arXiv.2111.09499},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@techreport{zhou_semantic_2018,
	title = {Semantic {Understanding} of {Scenes} through the {ADE20K} {Dataset}},
	url = {http://arxiv.org/abs/1608.05442},
	number = {arXiv:1608.05442},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
	month = oct,
	year = {2018},
	doi = {10.48550/arXiv.1608.05442},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{wang_pyramid_2021,
	title = {Pyramid {Vision} {Transformer}: {A} {Versatile} {Backbone} for {Dense} {Prediction} without {Convolutions}},
	shorttitle = {Pyramid {Vision} {Transformer}},
	url = {http://arxiv.org/abs/2102.12122},
	number = {arXiv:2102.12122},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
	month = aug,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	number = {arXiv:1810.04805},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	doi = {10.48550/arXiv.1810.04805},
	keywords = {Computer Science - Computation and Language},
}

@techreport{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	number = {arXiv:2010.11929},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	doi = {10.48550/arXiv.2010.11929},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@techreport{sandler_mobilenetv2_2019,
	title = {{MobileNetV2}: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	shorttitle = {{MobileNetV2}},
	url = {http://arxiv.org/abs/1801.04381},
	number = {arXiv:1801.04381},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	month = mar,
	year = {2019},
	doi = {10.48550/arXiv.1801.04381},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{howard_mobilenets_2017,
	title = {{MobileNets}: {Efficient} {Convolutional} {Neural} {Networks} for {Mobile} {Vision} {Applications}},
	shorttitle = {{MobileNets}},
	url = {http://arxiv.org/abs/1704.04861},
	number = {arXiv:1704.04861},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	month = apr,
	year = {2017},
	doi = {10.48550/arXiv.1704.04861},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{chen_rethinking_2017,
	title = {Rethinking {Atrous} {Convolution} for {Semantic} {Image} {Segmentation}},
	url = {http://arxiv.org/abs/1706.05587},
	number = {arXiv:1706.05587},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
	month = dec,
	year = {2017},
	doi = {10.48550/arXiv.1706.05587},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{zhao_icnet_2018,
	title = {{ICNet} for {Real}-{Time} {Semantic} {Segmentation} on {High}-{Resolution} {Images}},
	url = {http://arxiv.org/abs/1704.08545},
	number = {arXiv:1704.08545},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Zhao, Hengshuang and Qi, Xiaojuan and Shen, Xiaoyong and Shi, Jianping and Jia, Jiaya},
	month = aug,
	year = {2018},
	doi = {10.48550/arXiv.1704.08545},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{chen_semantic_2016,
	title = {Semantic {Image} {Segmentation} with {Deep} {Convolutional} {Nets} and {Fully} {Connected} {CRFs}},
	url = {http://arxiv.org/abs/1412.7062},
	number = {arXiv:1412.7062},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
	month = jun,
	year = {2016},
	doi = {10.48550/arXiv.1412.7062},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@techreport{liu_parsenet_2015,
	title = {{ParseNet}: {Looking} {Wider} to {See} {Better}},
	shorttitle = {{ParseNet}},
	url = {http://arxiv.org/abs/1506.04579},
	number = {arXiv:1506.04579},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Liu, Wei and Rabinovich, Andrew and Berg, Alexander C.},
	month = nov,
	year = {2015},
	doi = {10.48550/arXiv.1506.04579},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{sun_revisiting_2017,
	title = {Revisiting {Unreasonable} {Effectiveness} of {Data} in {Deep} {Learning} {Era}},
	url = {http://arxiv.org/abs/1707.02968},
	number = {arXiv:1707.02968},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
	month = aug,
	year = {2017},
	doi = {10.48550/arXiv.1707.02968},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
}

@techreport{russakovsky_imagenet_2015,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	url = {http://arxiv.org/abs/1409.0575},
	number = {arXiv:1409.0575},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	month = jan,
	year = {2015},
	doi = {10.48550/arXiv.1409.0575},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, I.4.8, I.5.2},
}

@techreport{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	number = {arXiv:1512.03385},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	doi = {10.48550/arXiv.1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	number = {arXiv:1409.1556},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	doi = {10.48550/arXiv.1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{girshick_rich_2014,
	title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
	url = {http://arxiv.org/abs/1311.2524},
	number = {arXiv:1311.2524},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	month = oct,
	year = {2014},
	doi = {10.48550/arXiv.1311.2524},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{richter_enhancing_2021,
	title = {Enhancing {Photorealism} {Enhancement}},
	url = {http://arxiv.org/abs/2105.04619},
	number = {arXiv:2105.04619},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Richter, Stephan R. and AlHaija, Hassan Abu and Koltun, Vladlen},
	month = may,
	year = {2021},
	doi = {10.48550/arXiv.2105.04619},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, I.4.8, Computer Science - Artificial Intelligence, Computer Science - Graphics},
}

@techreport{zhao_pyramid_2017,
	title = {Pyramid {Scene} {Parsing} {Network}},
	url = {http://arxiv.org/abs/1612.01105},
	number = {arXiv:1612.01105},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
	month = apr,
	year = {2017},
	doi = {10.48550/arXiv.1612.01105},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@incollection{he_spatial_2014,
	title = {Spatial {Pyramid} {Pooling} in {Deep} {Convolutional} {Networks} for {Visual} {Recognition}},
	volume = {8691},
	url = {http://arxiv.org/abs/1406.4729},
	urldate = {2022-06-04},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2014},
	doi = {10.1007/978-3-319-10578-9_23},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {346--361},
}

@techreport{gupta_learning_2014,
	title = {Learning {Rich} {Features} from {RGB}-{D} {Images} for {Object} {Detection} and {Segmentation}},
	url = {http://arxiv.org/abs/1407.5736},
	number = {arXiv:1407.5736},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Gupta, Saurabh and Girshick, Ross and Arbeláez, Pablo and Malik, Jitendra},
	month = jul,
	year = {2014},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@misc{noauthor_13112524_nodate,
	title = {[1311.2524] {Rich} feature hierarchies for accurate object detection and semantic segmentation},
	url = {https://arxiv.org/abs/1311.2524},
	urldate = {2022-06-04},
}

@article{hesamian_deep_2019,
	title = {Deep {Learning} {Techniques} for {Medical} {Image} {Segmentation}: {Achievements} and {Challenges}},
	volume = {32},
	issn = {1618-727X},
	shorttitle = {Deep {Learning} {Techniques} for {Medical} {Image} {Segmentation}},
	url = {https://doi.org/10.1007/s10278-019-00227-x},
	doi = {10.1007/s10278-019-00227-x},
	language = {en},
	number = {4},
	urldate = {2022-06-04},
	journal = {Journal of Digital Imaging},
	author = {Hesamian, Mohammad Hesam and Jia, Wenjing and He, Xiangjian and Kennedy, Paul},
	month = aug,
	year = {2019},
	keywords = {Deep learning, CNN, Medical image segmentation, Organ segmentation},
	pages = {582--596},
}

@techreport{chu_twins_2021,
	title = {Twins: {Revisiting} the {Design} of {Spatial} {Attention} in {Vision} {Transformers}},
	shorttitle = {Twins},
	url = {http://arxiv.org/abs/2104.13840},
	number = {arXiv:2104.13840},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
	month = sep,
	year = {2021},
	doi = {10.48550/arXiv.2104.13840},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@techreport{liu_swin_2021,
	title = {Swin {Transformer}: {Hierarchical} {Vision} {Transformer} using {Shifted} {Windows}},
	shorttitle = {Swin {Transformer}},
	url = {http://arxiv.org/abs/2103.14030},
	number = {arXiv:2103.14030},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	month = aug,
	year = {2021},
	doi = {10.48550/arXiv.2103.14030},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@techreport{touvron_training_2021,
	title = {Training data-efficient image transformers \& distillation through attention},
	url = {http://arxiv.org/abs/2012.12877},
	number = {arXiv:2012.12877},
	urldate = {2022-06-04},
	institution = {arXiv},
	author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jégou, Hervé},
	month = jan,
	year = {2021},
	doi = {10.48550/arXiv.2012.12877},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{poudel_contextnet_2018,
	title = {{ContextNet}: {Exploring} {Context} and {Detail} for {Semantic} {Segmentation} in {Real}-time},
	shorttitle = {{ContextNet}},
	url = {http://arxiv.org/abs/1805.04554},
	number = {arXiv:1805.04554},
	urldate = {2022-05-30},
	institution = {arXiv},
	author = {Poudel, Rudra P. K. and Bonde, Ujwal and Liwicki, Stephan and Zach, Christopher},
	month = nov,
	year = {2018},
	doi = {10.48550/arXiv.1805.04554},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{badrinarayanan_segnet_2016,
	title = {{SegNet}: {A} {Deep} {Convolutional} {Encoder}-{Decoder} {Architecture} for {Image} {Segmentation}},
	shorttitle = {{SegNet}},
	url = {http://arxiv.org/abs/1511.00561},
	number = {arXiv:1511.00561},
	urldate = {2022-05-30},
	institution = {arXiv},
	author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
	month = oct,
	year = {2016},
	doi = {10.48550/arXiv.1511.00561},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@techreport{paszke_enet_2016,
	title = {{ENet}: {A} {Deep} {Neural} {Network} {Architecture} for {Real}-{Time} {Semantic} {Segmentation}},
	shorttitle = {{ENet}},
	url = {http://arxiv.org/abs/1606.02147},
	number = {arXiv:1606.02147},
	urldate = {2022-05-30},
	institution = {arXiv},
	author = {Paszke, Adam and Chaurasia, Abhishek and Kim, Sangpil and Culurciello, Eugenio},
	month = jun,
	year = {2016},
	doi = {10.48550/arXiv.1606.02147},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{chollet_xception_2017,
	title = {Xception: {Deep} {Learning} with {Depthwise} {Separable} {Convolutions}},
	shorttitle = {Xception},
	url = {http://arxiv.org/abs/1610.02357},
	number = {arXiv:1610.02357},
	urldate = {2022-05-30},
	institution = {arXiv},
	author = {Chollet, François},
	month = apr,
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{minaee_image_2020,
	title = {Image {Segmentation} {Using} {Deep} {Learning}: {A} {Survey}},
	shorttitle = {Image {Segmentation} {Using} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2001.05566},
	number = {arXiv:2001.05566},
	urldate = {2022-05-27},
	institution = {arXiv},
	author = {Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
	month = nov,
	year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@techreport{chen_deeplab_2017,
	title = {{DeepLab}: {Semantic} {Image} {Segmentation} with {Deep} {Convolutional} {Nets}, {Atrous} {Convolution}, and {Fully} {Connected} {CRFs}},
	shorttitle = {{DeepLab}},
	url = {http://arxiv.org/abs/1606.00915},
	number = {arXiv:1606.00915},
	urldate = {2022-05-24},
	institution = {arXiv},
	author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
	month = may,
	year = {2017},
	doi = {10.48550/arXiv.1606.00915},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{long_fully_2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1411.4038},
	number = {arXiv:1411.4038},
	urldate = {2022-05-24},
	institution = {arXiv},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	month = mar,
	year = {2015},
	doi = {10.48550/arXiv.1411.4038},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{li_dispensed_2021,
	title = {Dispensed {Transformer} {Network} for {Unsupervised} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/2110.14944},
	number = {arXiv:2110.14944},
	urldate = {2022-05-17},
	institution = {arXiv},
	author = {Li, Yunxiang and Li, Jingxiong and Dan, Ruilong and Wang, Shuai and Jin, Kai and Zeng, Guodong and Wang, Jun and Pan, Xiangji and Zhang, Qianni and Zhou, Huiyu and Jin, Qun and Wang, Li and Wang, Yaqi},
	month = oct,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
}

@techreport{mehta_mobilevit_2022,
	title = {{MobileViT}: {Light}-weight, {General}-purpose, and {Mobile}-friendly {Vision} {Transformer}},
	shorttitle = {{MobileViT}},
	url = {http://arxiv.org/abs/2110.02178},
	number = {arXiv:2110.02178},
	urldate = {2022-05-17},
	institution = {arXiv},
	author = {Mehta, Sachin and Rastegari, Mohammad},
	month = mar,
	year = {2022},
	doi = {10.48550/arXiv.2110.02178},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@misc{noauthor_210805988_nodate,
	title = {[2108.05988] {TVT}: {Transferable} {Vision} {Transformer} for {Unsupervised} {Domain} {Adaptation}},
	url = {https://arxiv.org/abs/2108.05988},
	urldate = {2022-05-03},
}

@article{liang_domain_2021,
	title = {Domain {Adaptation} with {Auxiliary} {Target} {Domain}-{Oriented} {Classifier}},
	url = {http://arxiv.org/abs/2007.04171},
	urldate = {2022-04-25},
	journal = {arXiv:2007.04171 [cs]},
	author = {Liang, Jian and Hu, Dapeng and Feng, Jiashi},
	month = dec,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@incollection{zou_unsupervised_2018,
	address = {Cham},
	title = {Unsupervised {Domain} {Adaptation} for {Semantic} {Segmentation} via {Class}-{Balanced} {Self}-training},
	volume = {11207},
	isbn = {978-3-030-01218-2 978-3-030-01219-9},
	url = {http://link.springer.com/10.1007/978-3-030-01219-9_18},
	language = {en},
	urldate = {2022-04-18},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Zou, Yang and Yu, Zhiding and Vijaya Kumar, B. V. K. and Wang, Jinsong},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01219-9_18},
	pages = {297--313},
}

@article{borse_inverseform_2021,
	title = {{InverseForm}: {A} {Loss} {Function} for {Structured} {Boundary}-{Aware} {Segmentation}},
	shorttitle = {{InverseForm}},
	url = {http://arxiv.org/abs/2104.02745},
	urldate = {2022-04-18},
	journal = {arXiv:2104.02745 [cs]},
	author = {Borse, Shubhankar and Wang, Ying and Zhang, Yizhe and Porikli, Fatih},
	month = apr,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@inproceedings{sener_learning_2016,
	title = {Learning {Transferrable} {Representations} for {Unsupervised} {Domain} {Adaptation}},
	volume = {29},
	urldate = {2022-04-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Sener, Ozan and Song, Hyun Oh and Saxena, Ashutosh and Savarese, Silvio},
	year = {2016},
}

@article{zheng_rethinking_2021,
	title = {Rethinking {Semantic} {Segmentation} from a {Sequence}-to-{Sequence} {Perspective} with {Transformers}},
	url = {http://arxiv.org/abs/2012.15840},
	urldate = {2022-04-04},
	journal = {arXiv:2012.15840 [cs]},
	author = {Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip H. S. and Zhang, Li},
	month = jul,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{xie_segformer_2021,
	title = {{SegFormer}: {Simple} and {Efficient} {Design} for {Semantic} {Segmentation} with {Transformers}},
	shorttitle = {{SegFormer}},
	url = {http://arxiv.org/abs/2105.15203},
	urldate = {2022-03-28},
	journal = {arXiv:2105.15203 [cs]},
	author = {Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M. and Luo, Ping},
	month = oct,
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	urldate = {2022-03-28},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{chun_road_2019,
	title = {Road {Surface} {Damage} {Detection} {Using} {Fully} {Convolutional} {Neural} {Networks} and {Semi}-{Supervised} {Learning}},
	volume = {19},
	issn = {1424-8220},
	doi = {10.3390/s19245501},
	language = {eng},
	number = {24},
	journal = {Sensors (Basel, Switzerland)},
	author = {Chun, Chanjun and Ryu, Seung-Ki},
	month = dec,
	year = {2019},
	pmid = {31842513},
	pmcid = {PMC6961057},
	keywords = {semantic segmentation, autoencoder, convolutional neural network, road surface damage, semi-supervised learning},
	pages = {E5501},
}

@article{hamishebahar_comprehensive_2022,
	title = {A {Comprehensive} {Review} of {Deep} {Learning}-{Based} {Crack} {Detection} {Approaches}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/3/1374},
	doi = {10.3390/app12031374},
	language = {en},
	number = {3},
	urldate = {2022-03-21},
	journal = {Applied Sciences},
	author = {Hamishebahar, Younes and Guan, Hong and So, Stephen and Jo, Jun},
	month = jan,
	year = {2022},
	keywords = {semantic segmentation, deep learning, crack detection, image classification, object recognition, structural health monitoring},
	pages = {1374},
}

@inproceedings{szegedy_going_2015,
	title = {Going {Deeper} {With} {Convolutions}},
	booktitle = {Proc. {CVPR}},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = jun,
	year = {2015},
}

@article{badrinarayanan_segnet_2017,
	title = {Segnet: {A} deep convolutional encoder-decoder architecture for image segmentation},
	volume = {39},
	number = {12},
	journal = {IEEE TPAMI},
	author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
	year = {2017},
	note = {Publisher: IEEE},
	pages = {2481--2495},
}

@article{simonyan_very_2014,
	title = {Very deep convolutional networks for large-scale image recognition},
	journal = {arXiv preprint arXiv:1409.1556},
	author = {Simonyan, Karen and Zisserman, Andrew},
	year = {2014},
}

@article{targ_resnet_2016,
	title = {Resnet in resnet: {Generalizing} residual architectures},
	journal = {arXiv preprint arXiv:1603.08029},
	author = {Targ, Sasha and Almeida, Diogo and Lyman, Kevin},
	year = {2016},
}

@article{he_spatial_2015,
	title = {Spatial pyramid pooling in deep convolutional networks for visual recognition},
	volume = {37},
	number = {9},
	journal = {IEEE TPAMI},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2015},
	note = {Publisher: IEEE},
	pages = {1904--1916},
}

@inproceedings{fauqueur_assisted_2007,
	title = {Assisted video object labeling by joint tracking of regions and keypoints},
	booktitle = {Proc. {ICCV}},
	publisher = {IEEE},
	author = {Fauqueur, Julien and Brostow, Gabriel and Cipolla, Roberto},
	year = {2007},
	pages = {1--7},
}

@inproceedings{lin_feature_2017,
	title = {Feature pyramid networks for object detection},
	booktitle = {Proc. {CVPR}},
	author = {Lin, Tsung-Yi and Dollár, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
	year = {2017},
	pages = {2117--2125},
}

@inproceedings{liu_path_2018,
	title = {Path aggregation network for instance segmentation},
	booktitle = {Proc. {CVPR}},
	author = {Liu, Shu and Qi, Lu and Qin, Haifang and Shi, Jianping and Jia, Jiaya},
	year = {2018},
	pages = {8759--8768},
}

@inproceedings{pinheiro_learning_2016,
	title = {Learning to refine object segments},
	booktitle = {Proc. {ECCV}},
	publisher = {Springer},
	author = {Pinheiro, Pedro O and Lin, Tsung-Yi and Collobert, Ronan and Dollár, Piotr},
	year = {2016},
	pages = {75--91},
}

@article{sergeev_horovod_2018,
	title = {Horovod: fast and easy distributed deep learning in {TensorFlow}},
	journal = {arXiv preprint arXiv:1802.05799},
	author = {Sergeev, Alexander and Del Balso, Mike},
	year = {2018},
}

@article{brostow_semantic_2009,
	title = {Semantic object classes in video: {A} high-definition ground truth database},
	volume = {30},
	number = {2},
	journal = {Pattern Recognition Letters},
	author = {Brostow, Gabriel J and Fauqueur, Julien and Cipolla, Robertof},
	year = {2009},
	note = {Publisher: Elsevier},
	pages = {88--97},
}

@inproceedings{yu_bdd100k_2020,
	title = {{BDD100k}: {A} diverse driving dataset for heterogeneous multitask learning},
	booktitle = {Proc. {CVPR}},
	author = {Yu, Fisher and Chen, Haofeng and Wang, Xin and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Madhavan, Vashisht and Darrell, Trevor},
	year = {2020},
	pages = {2636--2645},
}

@inproceedings{treml_speeding_2016,
	title = {Speeding up semantic segmentation for autonomous driving},
	volume = {2},
	booktitle = {{MLITS}, {NIPS} {Workshop}},
	author = {Treml, Michael and Arjona-Medina, José and Unterthiner, Thomas and Durgesh, Rupesh and Friedmann, Felix and Schuberth, Peter and Mayr, Andreas and Heusel, Martin and Hofmarcher, Markus and Widrich, Michael and {others}},
	year = {2016},
	note = {Issue: 7},
}

@article{wu_wider_2019,
	title = {Wider or deeper: {Revisiting} the resnet model for visual recognition},
	volume = {90},
	journal = {Pattern Recognition},
	author = {Wu, Zifeng and Shen, Chunhua and Van Den Hengel, Anton},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {119--133},
}

@article{yuan_object-contextual_2019,
	title = {Object-contextual representations for semantic segmentation},
	journal = {arXiv preprint arXiv:1909.11065},
	author = {Yuan, Yuhui and Chen, Xilin and Wang, Jingdong},
	year = {2019},
}

@inproceedings{choi_cars_2020,
	title = {Cars {Can}'t {Fly} {Up} in the {Sky}: {Improving} {Urban}-{Scene} {Segmentation} via {Height}-{Driven} {Attention} {Networks}},
	booktitle = {Proc. {CVPR}},
	author = {Choi, Sungha and Kim, Joanne T and Choo, Jaegul},
	year = {2020},
	pages = {9373--9383},
}

@article{wu_real-time_2017,
	title = {Real-time semantic image segmentation via spatial sparsity},
	journal = {arXiv preprint arXiv:1712.00213},
	author = {Wu, Zifeng and Shen, Chunhua and Hengel, Anton van den},
	year = {2017},
}

@article{kendall_bayesian_2015,
	title = {Bayesian segnet: {Model} uncertainty in deep convolutional encoder-decoder architectures for scene understanding},
	journal = {arXiv preprint arXiv:1511.02680},
	author = {Kendall, Alex and Badrinarayanan, Vijay and Cipolla, Roberto},
	year = {2015},
}

@inproceedings{he_dynamic_2019,
	title = {Dynamic multi-scale filters for semantic segmentation},
	booktitle = {Proc. {ICCV}},
	author = {He, Junjun and Deng, Zhongying and Qiao, Yu},
	year = {2019},
	pages = {3562--3572},
}

@article{hong_deep_2021,
	title = {Deep dual-resolution networks for real-time and accurate semantic segmentation of road scenes},
	journal = {arXiv preprint arXiv:2101.06085},
	author = {Hong, Yuanduo and Pan, Huihui and Sun, Weichao and Jia, Yisong and {others}},
	year = {2021},
}

@inproceedings{luo_lightweight_2020,
	title = {A {Lightweight} {Network} for {Fast} {Semantic} {Segmentation}},
	booktitle = {Proc. {BESC}},
	publisher = {IEEE},
	author = {Luo, Ruiqi and Cao, Yuanzhouhan and Jin, Yi and Li, Yidong},
	year = {2020},
	pages = {1--6},
}

@inproceedings{chen_encoder-decoder_2018,
	title = {Encoder-decoder with atrous separable convolution for semantic image segmentation},
	booktitle = {Proc. {ECCV}},
	author = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
	year = {2018},
	pages = {801--818},
}

@article{tao_hierarchical_2020,
	title = {Hierarchical multi-scale attention for semantic segmentation},
	journal = {arXiv preprint arXiv:2005.10821},
	author = {Tao, Andrew and Sapra, Karan and Catanzaro, Bryan},
	year = {2020},
}

@inproceedings{singha_fanet_2020,
	title = {{FANet}: {Feature} {Aggregation} {Network} for {Semantic} {Segmentation}},
	booktitle = {Proc. {DICTA}},
	publisher = {IEEE},
	author = {Singha, Tanmay and Pham, Duc-Son and Krishna, Aneesh},
	year = {2020},
	pages = {1--8},
}

@inproceedings{singha_efficient_2020,
	title = {Efficient {Segmentation} {Pyramid} {Network}},
	booktitle = {Proc. {ICONIP}},
	publisher = {Springer},
	author = {Singha, Tanmay and Pham, Duc-Son and Krishna, Aneesh and Dunstan, Joel},
	year = {2020},
	pages = {386--393},
}

@inproceedings{zhang_road_2016,
	title = {Road crack detection using deep convolutional neural network},
	booktitle = {Proc. {ICIP}},
	publisher = {IEEE},
	author = {Zhang, Lei and Yang, Fan and Zhang, Yimin Daniel and Zhu, Ying Julie},
	year = {2016},
	pages = {3708--3712},
}

@inproceedings{pohlen_full-resolution_2017,
	title = {Full-resolution residual networks for semantic segmentation in street scenes},
	booktitle = {Proc. {CVPR}},
	author = {Pohlen, Tobias and Hermans, Alexander and Mathias, Markus and Leibe, Bastian},
	year = {2017},
	pages = {4151--4160},
}

@article{nayyeri_foregroundbackground_2019,
	title = {Foreground–background separation technique for crack detection},
	volume = {34},
	number = {6},
	journal = {Computer-Aided Civil and Infrastructure Engineering},
	author = {Nayyeri, Fereshteh and Hou, Lei and Zhou, Jun and Guan, Hong},
	year = {2019},
	note = {Publisher: Wiley Online Library},
	pages = {457--470},
}

@article{liu_deepcrack_2019,
	title = {{DeepCrack}: {A} deep hierarchical feature learning architecture for crack segmentation},
	volume = {338},
	journal = {Neurocomputing},
	author = {Liu, Yahui and Yao, Jian and Lu, Xiaohu and Xie, Renping and Li, Li},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {139--153},
}

@inproceedings{nayyeri_multi-resolution_2021,
	title = {Multi-{Resolution} {ResNet} for {Road} and {Bridge} {Crack} {Detection}},
	booktitle = {Proc. {DICTA}},
	publisher = {IEEE},
	author = {Nayyeri, Fereshteh and Zhou, Jun},
	year = {2021},
	pages = {1--8},
}

@article{yang_feature_2019,
	title = {Feature pyramid and hierarchical boosting network for pavement crack detection},
	volume = {21},
	number = {4},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Yang, Fan and Zhang, Lei and Yu, Sijia and Prokhorov, Danil and Mei, Xue and Ling, Haibin},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {1525--1535},
}

@article{choi_sddnet_2019,
	title = {{SDDNet}: {Real}-time {Crack} {Segmentation}},
	volume = {PP},
	shorttitle = {{SDDNet}},
	doi = {10.1109/TIE.2019.2945265},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Choi, Wooram and Cha, Young-Jin},
	month = oct,
	year = {2019},
	pages = {1--1},
}

@article{kang_efficient_2021,
	title = {Efficient attention-based deep encoder and decoder for automatic crack segmentation},
	journal = {Structural Health Monitoring},
	author = {Kang, Dong H and Cha, Young-Jin},
	month = dec,
	year = {2021},
	pages = {14759217211053776},
}

@inproceedings{singha_scmnet_2021,
	title = {{SCMNet}: {Shared} {Context} {Mining} {Network} for {Real}-time {Semantic} {Segmentation}},
	booktitle = {Proc. {DICTA}},
	publisher = {IEEE},
	author = {Singha, Tanmay and Bergemann, Moritz and Pham, Duc-Son and Krishna, Aneesh},
	year = {2021},
	pages = {1--8},
}

@article{everingham_pascal_2015,
	title = {The pascal visual object classes challenge: {A} retrospective},
	volume = {111},
	number = {1},
	journal = {IJCV},
	author = {Everingham, Mark and Eslami, SM and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
	year = {2015},
	pages = {98--136},
}

@article{goyal_accurate_2017,
	title = {Accurate, large minibatch {SGD}: {Training} {ImageNet} in 1 hour},
	journal = {arXiv preprint arXiv:1706.02677},
	author = {Goyal, Priya and Dollár, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
	year = {2017},
}

@inproceedings{david_jenkins_deep_2018,
	title = {A {Deep} {Convolutional} {Neural} {Network} for {Semantic} {Pixel}-{Wise} {Segmentation} of {Road} and {Pavement} {Surface} {Cracks}},
	doi = {10.23919/EUSIPCO.2018.8553280},
	booktitle = {Proc. {EUSIPCO}},
	author = {David Jenkins, Mark and Carr, Thomas Arthur and Iglesias, Maria Insa and Buggy, Tom and Morison, Gordon},
	month = sep,
	year = {2018},
	pages = {2120--2124},
}

@article{chen_pavement_2020,
	title = {Pavement crack detection and recognition using the architecture of {segNet}},
	volume = {18},
	journal = {Journal of Industrial Information Integration},
	author = {Chen, Tingyang and Cai, Zhenhua and Zhao, Xi and Chen, Chen and Liang, Xufeng and Zou, Tierui and Wang, Pan},
	month = jun,
	year = {2020},
	pages = {100144},
}

@inproceedings{eisenbach_how_2017,
	title = {How to {Get} {Pavement} {Distress} {Detection} {Ready} for {Deep} {Learning}? {A} {Systematic} {Approach}.},
	booktitle = {Proc. {IJCNN}},
	author = {Eisenbach, Markus and Stricker, Ronny and Seichter, Daniel and Amende, Karl and Debes, Klaus and Sesselmann, Maximilian and Ebersbach, Dirk and Stoeckert, Ulrike and Gross, Horst-Michael},
	year = {2017},
	pages = {2039--2047},
}

@article{shi_automatic_2016,
	title = {Automatic road crack detection using random structured forests},
	volume = {17},
	number = {12},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Shi, Yong and Cui, Limeng and Qi, Zhiquan and Meng, Fan and Chen, Zhensong},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {3434--3445},
}

@article{amhaz_automatic_2016,
	title = {Automatic crack detection on two-dimensional pavement images: {An} algorithm based on minimal path selection},
	volume = {17},
	number = {10},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Amhaz, Rabih and Chambon, Sylvie and Idier, Jérôme and Baltazart, Vincent},
	year = {2016},
	note = {Publisher: IEEE},
	pages = {2718--2729},
}

@article{zou_cracktree_2012,
	title = {{CrackTree}: {Automatic} crack detection from pavement images},
	volume = {33},
	number = {3},
	journal = {Pattern Recognition Letters},
	author = {Zou, Qin and Cao, Yu and Li, Qingquan and Mao, Qingzhou and Wang, Song},
	year = {2012},
	note = {Publisher: Elsevier},
	pages = {227--238},
}

@article{ali_real-time_2021,
	title = {Real-time multiple damage mapping using autonomous {UAV} and deep faster region-based neural networks for {GPS}-denied structures},
	volume = {130},
	journal = {Automation in Construction},
	author = {Ali, Rahmat and Kang, Dongho and Suh, Gahyun and Cha, Young-Jin},
	month = oct,
	year = {2021},
	pages = {103831},
}

@article{kerle_uav-based_2020,
	title = {{UAV}-{Based} {Structural} {Damage} {Mapping}: {A} {Review}},
	volume = {9},
	number = {1},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Kerle, Norman and Nex, Francesco and Gerke, Markus and Duarte, Diogo and Vetrivel, Anand},
	month = jan,
	year = {2020},
	pages = {14},
}

@article{kang_autonomous_2018,
	title = {Autonomous {UAVs} for {Structural} {Health} {Monitoring} {Using} {Deep} {Learning} and an {Ultrasonic} {Beacon} {System} with {Geo}-{Tagging}},
	volume = {33},
	issn = {1467-8667},
	doi = {10.1111/mice.12375},
	language = {en},
	number = {10},
	journal = {Computer-Aided Civil and Infrastructure Engineering},
	author = {Kang, Dongho and Cha, Young-Jin},
	year = {2018},
	pages = {885--902},
}

@misc{abraham_novel_2018,
	title = {A {Novel} {Focal} {Tversky} loss function with improved {Attention} {U}-{Net} for lesion segmentation},
	publisher = {arXiv},
	author = {Abraham, Nabila and Khan, Naimul Mefraz},
	month = oct,
	year = {2018},
	doi = {10.48550/arXiv.1810.07842},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{hoyer_daformer_2022,
	title = {{DAFormer}: {Improving} {Network} {Architectures} and {Training} {Strategies} for {Domain}-{Adaptive} {Semantic} {Segmentation}},
	shorttitle = {{DAFormer}},
	url = {http://arxiv.org/abs/2111.14887},
	doi = {10.48550/arXiv.2111.14887},
	abstract = {As acquiring pixel-wise annotations of real-world images for semantic segmentation is a costly process, a model can instead be trained with more accessible synthetic data and adapted to real images without requiring their annotations. This process is studied in unsupervised domain adaptation (UDA). Even though a large number of methods propose new adaptation strategies, they are mostly based on outdated network architectures. As the influence of recent network architectures has not been systematically studied, we first benchmark different network architectures for UDA and newly reveal the potential of Transformers for UDA semantic segmentation. Based on the findings, we propose a novel UDA method, DAFormer. The network architecture of DAFormer consists of a Transformer encoder and a multi-level context-aware feature fusion decoder. It is enabled by three simple but crucial training strategies to stabilize the training and to avoid overfitting to the source domain: While (1) Rare Class Sampling on the source domain improves the quality of the pseudo-labels by mitigating the confirmation bias of self-training toward common classes, (2) a Thing-Class ImageNet Feature Distance and (3) a learning rate warmup promote feature transfer from ImageNet pretraining. DAFormer represents a major advance in UDA. It improves the state of the art by 10.8 mIoU for GTA-to-Cityscapes and 5.4 mIoU for Synthia-to-Cityscapes and enables learning even difficult classes such as train, bus, and truck well. The implementation is available at https://github.com/lhoyer/DAFormer.},
	urldate = {2023-02-19},
	publisher = {arXiv},
	author = {Hoyer, Lukas and Dai, Dengxin and Van Gool, Luc},
	month = mar,
	year = {2022},
	note = {arXiv:2111.14887 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/moritz/snap/zotero-snap/common/Zotero/storage/9EWNPK5R/Hoyer et al. - 2022 - DAFormer Improving Network Architectures and Trai.pdf:application/pdf;arXiv.org Snapshot:/home/moritz/snap/zotero-snap/common/Zotero/storage/B4MQVQMI/2111.html:text/html},
}

@article{kochkarev_data_2020,
	title = {Data {Balancing} {Method} for {Training} {Segmentation} {Neural} {Networks}},
	url = {http://ceur-ws.org/Vol-2744/short19.pdf},
	doi = {10.51130/graphicon-2020-2-4-19},
	language = {en},
	urldate = {2023-02-23},
	journal = {Proceedings of the 30th International Conference on Computer Graphics and Machine Vision (GraphiCon 2020). Part 2},
	author = {Kochkarev, Alexey and Khvostikov, Alexander and Korshunov, Dmitry and Krylov, Andrey and Boguslavskiy, Mikhail},
	month = dec,
	year = {2020},
	pages = {short19--1--short19--9},
	file = {Kochkarev et al. - 2020 - Data Balancing Method for Training Segmentation Ne.pdf:/home/moritz/snap/zotero-snap/common/Zotero/storage/5LBMBB9X/Kochkarev et al. - 2020 - Data Balancing Method for Training Segmentation Ne.pdf:application/pdf},
}

@article{kochkarev_data_2020-1,
	title = {Data {Balancing} {Method} for {Training} {Segmentation} {Neural} {Networks}},
	url = {http://ceur-ws.org/Vol-2744/short19.pdf},
	doi = {10.51130/graphicon-2020-2-4-19},
	abstract = {Data imbalance is a common problem in machine learning and image processing. The lack of training data for the rarest classes can lead to worse learning ability and negatively affect the quality of segmentation. In this paper we focus on the problem of data balancing for the task of image segmentation. We review major trends in handling unbalanced data and propose a new method for data balancing, based on Distance Transform. This method is designed for using in segmentation convolutional neural networks (CNNs), but it is universal and can be used with any patch-based segmentation machine learning model. The evaluation of the proposed data balancing method is performed on two datasets. The ﬁrst is medical dataset LiTS, containing CT images of liver with tumor abnormalities. Second one is a geological dataset, containing of photographs of polished sections of different ores. The proposed algorithm enhances the data balance between classes and improves the overall performance of CNN model.},
	language = {en},
	urldate = {2023-02-23},
	journal = {Proceedings of the 30th International Conference on Computer Graphics and Machine Vision (GraphiCon 2020). Part 2},
	author = {Kochkarev, Alexey and Khvostikov, Alexander and Korshunov, Dmitry and Krylov, Andrey and Boguslavskiy, Mikhail},
	month = dec,
	year = {2020},
	pages = {short19--1--short19--9},
	file = {Kochkarev et al. - 2020 - Data Balancing Method for Training Segmentation Ne.pdf:/home/moritz/snap/zotero-snap/common/Zotero/storage/NVEECJS9/Kochkarev et al. - 2020 - Data Balancing Method for Training Segmentation Ne.pdf:application/pdf},
}

@misc{wilson_survey_2020,
	title = {A {Survey} of {Unsupervised} {Deep} {Domain} {Adaptation}},
	url = {http://arxiv.org/abs/1812.02849},
	doi = {10.48550/arXiv.1812.02849},
	abstract = {Deep learning has produced state-of-the-art results for a variety of tasks. While such approaches for supervised learning have performed well, they assume that training and testing data are drawn from the same distribution, which may not always be the case. As a complement to this challenge, single-source unsupervised domain adaptation can handle situations where a network is trained on labeled data from a source domain and unlabeled data from a related but different target domain with the goal of performing well at test-time on the target domain. Many single-source and typically homogeneous unsupervised deep domain adaptation approaches have thus been developed, combining the powerful, hierarchical representations from deep learning with domain adaptation to reduce reliance on potentially-costly target data labels. This survey will compare these approaches by examining alternative methods, the unique and common elements, results, and theoretical insights. We follow this with a look at application areas and open research directions.},
	urldate = {2023-03-07},
	publisher = {arXiv},
	author = {Wilson, Garrett and Cook, Diane J.},
	month = feb,
	year = {2020},
	note = {arXiv:1812.02849 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/moritz/snap/zotero-snap/common/Zotero/storage/WBUD6G2S/Wilson and Cook - 2020 - A Survey of Unsupervised Deep Domain Adaptation.pdf:application/pdf;arXiv.org Snapshot:/home/moritz/snap/zotero-snap/common/Zotero/storage/SCL4XVII/1812.html:text/html},
}

@misc{tsai_learning_2020,
	title = {Learning to {Adapt} {Structured} {Output} {Space} for {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1802.10349},
	doi = {10.48550/arXiv.1802.10349},
	abstract = {Convolutional neural network-based approaches for semantic segmentation rely on supervision with pixel-level ground truth, but may not generalize well to unseen image domains. As the labeling process is tedious and labor intensive, developing algorithms that can adapt source ground truth labels to the target domain is of great interest. In this paper, we propose an adversarial learning method for domain adaptation in the context of semantic segmentation. Considering semantic segmentations as structured outputs that contain spatial similarities between the source and target domains, we adopt adversarial learning in the output space. To further enhance the adapted model, we construct a multi-level adversarial network to effectively perform output space domain adaptation at different feature levels. Extensive experiments and ablation study are conducted under various domain adaptation settings, including synthetic-to-real and cross-city scenarios. We show that the proposed method performs favorably against the state-of-the-art methods in terms of accuracy and visual quality.},
	urldate = {2023-03-09},
	publisher = {arXiv},
	author = {Tsai, Yi-Hsuan and Hung, Wei-Chih and Schulter, Samuel and Sohn, Kihyuk and Yang, Ming-Hsuan and Chandraker, Manmohan},
	month = jul,
	year = {2020},
	note = {arXiv:1802.10349 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/moritz/snap/zotero-snap/common/Zotero/storage/W2JWP4SN/Tsai et al. - 2020 - Learning to Adapt Structured Output Space for Sema.pdf:application/pdf;arXiv.org Snapshot:/home/moritz/snap/zotero-snap/common/Zotero/storage/DL65I7DJ/1802.html:text/html},
}

@misc{wang_classes_2020,
	title = {Classes {Matter}: {A} {Fine}-grained {Adversarial} {Approach} to {Cross}-domain {Semantic} {Segmentation}},
	shorttitle = {Classes {Matter}},
	url = {http://arxiv.org/abs/2007.09222},
	doi = {10.48550/arXiv.2007.09222},
	abstract = {Despite great progress in supervised semantic segmentation,a large performance drop is usually observed when deploying the model in the wild. Domain adaptation methods tackle the issue by aligning the source domain and the target domain. However, most existing methods attempt to perform the alignment from a holistic view, ignoring the underlying class-level data structure in the target domain. To fully exploit the supervision in the source domain, we propose a fine-grained adversarial learning strategy for class-level feature alignment while preserving the internal structure of semantics across domains. We adopt a fine-grained domain discriminator that not only plays as a domain distinguisher, but also differentiates domains at class level. The traditional binary domain labels are also generalized to domain encodings as the supervision signal to guide the fine-grained feature alignment. An analysis with Class Center Distance (CCD) validates that our fine-grained adversarial strategy achieves better class-level alignment compared to other state-of-the-art methods. Our method is easy to implement and its effectiveness is evaluated on three classical domain adaptation tasks, i.e., GTA5 to Cityscapes, SYNTHIA to Cityscapes and Cityscapes to Cross-City. Large performance gains show that our method outperforms other global feature alignment based and class-wise alignment based counterparts. The code is publicly available at https://github.com/JDAI-CV/FADA.},
	urldate = {2023-03-09},
	publisher = {arXiv},
	author = {Wang, Haoran and Shen, Tong and Zhang, Wei and Duan, Lingyu and Mei, Tao},
	month = jul,
	year = {2020},
	note = {arXiv:2007.09222 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/moritz/snap/zotero-snap/common/Zotero/storage/WDA9JRCJ/Wang et al. - 2020 - Classes Matter A Fine-grained Adversarial Approac.pdf:application/pdf;arXiv.org Snapshot:/home/moritz/snap/zotero-snap/common/Zotero/storage/AACVT9F4/2007.html:text/html},
}

@misc{michieli_adversarial_2020,
	title = {Adversarial {Learning} and {Self}-{Teaching} {Techniques} for {Domain} {Adaptation} in {Semantic} {Segmentation}},
	url = {http://arxiv.org/abs/1909.00781},
	doi = {10.48550/arXiv.1909.00781},
	abstract = {Deep learning techniques have been widely used in autonomous driving systems for the semantic understanding of urban scenes. However, they need a huge amount of labeled data for training, which is difficult and expensive to acquire. A recently proposed workaround is to train deep networks using synthetic data, but the domain shift between real world and synthetic representations limits the performance. In this work, a novel Unsupervised Domain Adaptation (UDA) strategy is introduced to solve this issue. The proposed learning strategy is driven by three components: a standard supervised learning loss on labeled synthetic data; an adversarial learning module that exploits both labeled synthetic data and unlabeled real data; finally, a self-teaching strategy applied to unlabeled data. The last component exploits a region growing framework guided by the segmentation confidence. Furthermore, we weighted this component on the basis of the class frequencies to enhance the performance on less common classes. Experimental results prove the effectiveness of the proposed strategy in adapting a segmentation network trained on synthetic datasets, like GTA5 and SYNTHIA, to real world datasets like Cityscapes and Mapillary.},
	urldate = {2023-03-11},
	publisher = {arXiv},
	author = {Michieli, Umberto and Biasetton, Matteo and Agresti, Gianluca and Zanuttigh, Pietro},
	month = mar,
	year = {2020},
	note = {arXiv:1909.00781 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/home/moritz/snap/zotero-snap/common/Zotero/storage/J3G9C2G8/Michieli et al. - 2020 - Adversarial Learning and Self-Teaching Techniques .pdf:application/pdf;arXiv.org Snapshot:/home/moritz/snap/zotero-snap/common/Zotero/storage/4CMPNXXE/1909.html:text/html},
}

@misc{howard_searching_2019,
	title = {Searching for {MobileNetV3}},
	url = {http://arxiv.org/abs/1905.02244},
	doi = {10.48550/arXiv.1905.02244},
	abstract = {We present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design. MobileNetV3 is tuned to mobile phone CPUs through a combination of hardware-aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and network design can work together to harness complementary approaches improving the overall state of the art. Through this process we create two new MobileNet models for release: MobileNetV3-Large and MobileNetV3-Small which are targeted for high and low resource use cases. These models are then adapted and applied to the tasks of object detection and semantic segmentation. For the task of semantic segmentation (or any dense pixel prediction), we propose a new efficient segmentation decoder Lite Reduced Atrous Spatial Pyramid Pooling (LR-ASPP). We achieve new state of the art results for mobile classification, detection and segmentation. MobileNetV3-Large is 3.2{\textbackslash}\% more accurate on ImageNet classification while reducing latency by 15{\textbackslash}\% compared to MobileNetV2. MobileNetV3-Small is 4.6{\textbackslash}\% more accurate while reducing latency by 5{\textbackslash}\% compared to MobileNetV2. MobileNetV3-Large detection is 25{\textbackslash}\% faster at roughly the same accuracy as MobileNetV2 on COCO detection. MobileNetV3-Large LR-ASPP is 30{\textbackslash}\% faster than MobileNetV2 R-ASPP at similar accuracy for Cityscapes segmentation.},
	urldate = {2023-03-17},
	publisher = {arXiv},
	author = {Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and Le, Quoc V. and Adam, Hartwig},
	month = nov,
	year = {2019},
	note = {arXiv:1905.02244 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/moritz/snap/zotero-snap/common/Zotero/storage/AFH73BNL/Howard et al. - 2019 - Searching for MobileNetV3.pdf:application/pdf;arXiv.org Snapshot:/home/moritz/snap/zotero-snap/common/Zotero/storage/4MY7APR8/1905.html:text/html},
}